---
title: "Scoliosis Model"
author: "Caio Vallio"
abstract: |
  **Contexto:** A escoliose idiopática do adolescente pode apresentar resposta clínica variável a intervenções conservadoras.  
  **Objetivo:** Explorar associações entre características basais e melhora radiográfica em 6 meses.  
  **Métodos:** Estudo observacional com análise exploratória e inferencial. O desfecho contínuo foi $\Delta$ (maior curva em 6 meses − baseline, em graus). O desfecho binário (MCID) foi melhora definida como $\Delta \le -5°$. Ajustamos um modelo linear para $\Delta$ e um modelo logístico para o MCID, reportando estimativas com IC95% e verificações de adequação dos modelos.  
date: last-modified
format: 
  html:
    self-contained: true
    df-print: paged
    toc: true 
    toc-depth: 5
    number-sections: true
    number-depth: 5
    code-fold: true
execute: 
  echo: true
  warning: false
  message: false
  error: false
  freeze: auto
lang: pt-BR
#bibliography: references.bib
---

## Como reproduzir

- O arquivo de dados é lido de `data/modelagem final.xlsx` (aba `dados`).
- As análises dependem de pacotes R listados no chunk de setup; caso algum pacote esteja ausente, o documento interrompe a execução com uma mensagem explícita.

## Objetivo e delineamento

Este é um relatório **exploratório e inferencial**: o objetivo é **estimar associações ajustadas** entre variáveis basais e a evolução radiográfica em 6 meses.

## Definições de desfecho

- **Desfecho contínuo:** $\Delta$ = (maior curva em 6 meses − maior curva baseline), em graus. Valores mais negativos indicam maior melhora.  
- **Desfecho binário (MCID):** melhora clínica definida como $\Delta \le -5°$ (redução de pelo menos 5 graus).

## Plano de análise estatística

- **Descrição da amostra**: estatísticas descritivas das variáveis basais e do desfecho.
- **Inferência (associações ajustadas)**:
  - **Modelo linear** para $\Delta$ (efeitos como betas, IC95%).
  - **Modelo logístico** para MCID (efeitos como odds ratios, IC95%).
- **Adequação dos modelos**: diagnósticos de assunções (colinearidade, resíduos, heteroscedasticidade quando aplicável) e medidas de qualidade de ajuste (por exemplo, $R^2$).
- **Forma funcional**: para preditores contínuos, assume-se relação aproximadamente linear.

Por se tratar de análise **exploratória**, os resultados devem ser interpretados com cautela, com ênfase em **magnitude/direção** e incerteza (IC95%).


```{r}
## Setup (reprodutibilidade)
pkgs <- c(
    "tidyverse",
    "gtsummary",
    "readxl",
    "janitor",
    "performance",
    "qqplotr",
    "PupillometryR"
)
missing_pkgs <- pkgs[
    !vapply(pkgs, requireNamespace, logical(1), quietly = TRUE)
]
if (length(missing_pkgs) > 0) {
    stop("Pacotes ausentes: ", paste(missing_pkgs, collapse = ", "))
}
invisible(lapply(pkgs, library, character.only = TRUE))

set.seed(123)
theme_set(theme_minimal())


# read data
df_raw <- readxl::read_excel(
    "data/dataset_escoliose_00.xlsx",
    sheet = "dados",
    na = ""
)

# clean names
df <- df_raw |> janitor::clean_names()

# escoliometro - classificacao do local onde a escoliose esta mais severa
df <- df |>
    mutate(
        escoliometro_maior_10_graus = case_when(
            (escoliometro_cervical > 10) &
                (escoliometro_torarica > 10) &
                (escoliometro_lombar > 10) ~ "cervical_toracica_lombar",
            (escoliometro_cervical > 10) &
                (escoliometro_torarica > 10) ~ "cervical_toracica",
            (escoliometro_cervical > 10) &
                (escoliometro_lombar > 10) ~ "cervical_lombar",
            (escoliometro_torarica > 10) &
                (escoliometro_lombar > 10) ~ "toracica_lombar",
            (escoliometro_cervical > 10) ~ "cervical",
            (escoliometro_torarica > 10) ~ "toracica",
            (escoliometro_lombar > 10) ~ "lombar",
            TRUE ~ "nenhum"
        )
    )

# lenke - classificacao da curvatura da escoliose
df <- df |>
    mutate(
        lenke_curvatura = case_when(
            lenke %in% c(1, 2, 5) ~ "curva em c",
            lenke %in% c(3, 4, 6) ~ "curva em s",
            TRUE ~ NA_character_
        )
    )

# risser - classificacao do inicio e final do crescimento
df <- df |>
    mutate(
        risser_agrupado = case_when(
            risser %in% c(0, 1, 2) ~ "inicio do crescimento",
            risser %in% c(3, 4) ~ "final do crescimento",
            TRUE ~ NA_character_
        )
    )

# cifose - classificacao da cifose
df <- df |>
    mutate(
        cifose_categ = case_when(
            cifose_toracica < 10 ~ "hipocifose",
            cifose_toracica >= 10 & cifose_toracica < 40 ~ "normalidade",
            cifose_toracica >= 40 ~ "hipercifose",
            TRUE ~ NA_character_
        )
    )

# lordose - classificacao da lordose
df <- df |>
    mutate(
        lordose_categ = case_when(
            lordose_lombar < 45 ~ "hipolordose",
            lordose_lombar >= 45 & lordose_lombar < 50 ~ "normalidade",
            lordose_lombar >= 50 ~ "hiperlordose",
            TRUE ~ NA_character_
        )
    )

# imc - calculo do imc
df <- df |>
    mutate(
        imc = peso / (altura)^2
    )

# definicao do desfecho - alvo
# cobb inicial - alvo
df <- df |>
    mutate(
        cobb_inicial_maior = pmax(
            cobb_toracico_proximal,
            cobb_toracica,
            cobb_lombar,
            na.rm = TRUE
        )
    ) |>
    mutate(
        regiao_cobb_inicial = case_when(
            cobb_inicial_maior == cobb_toracico_proximal ~ "toracico_proximal",
            cobb_inicial_maior == cobb_toracica ~ "toracica",
            cobb_inicial_maior == cobb_lombar ~ "lombar",
            TRUE ~ NA_character_
        )
    )

# categorizacao do desfecho - alvo
df <- df |>
    mutate(delta = maior_curva_6_meses - cobb_inicial_maior) |>
    mutate(delta_cat = if_else(delta <= -5, 1, 0)) |>
    mutate(
        delta_cat_f = factor(
            delta_cat,
            levels = c(0, 1),
            labels = c("Sem melhora (MCID)", "Melhora (MCID)")
        )
    )

# casting de variaveis (garantir tipos adequados no ajuste)
df <- df |>
    mutate(
        idade = as.double(idade),
        lenke = as.factor(lenke),
        risser = as.factor(risser),
        sexo = as.factor(sexo),
        flexibilidade = as.factor(flexibilidade),
        regiao_cobb_inicial = as.factor(regiao_cobb_inicial),
        escoliometro_maior_10_graus = as.factor(escoliometro_maior_10_graus),
        lenke_curvatura = as.factor(lenke_curvatura),
        risser_agrupado = as.factor(risser_agrupado),
        cifose_categ = as.factor(cifose_categ),
        lordose_categ = as.factor(lordose_categ)
    )

```

## Dados faltantes e tamanho amostral

```{r}
missing_tbl <- df |>
    summarise(across(everything(), ~ sum(is.na(.)))) |>
    pivot_longer(
        everything(),
        names_to = "variavel",
        values_to = "n_missing"
    ) |>
    mutate(pct_missing = n_missing / nrow(df)) |>
    arrange(desc(pct_missing))

missing_tbl |>
    mutate(pct_missing = scales::percent(pct_missing, accuracy = 0.1)) |>
    print(n = 50)


# drop na in flexibilidade
df <- df |> drop_na(flexibilidade)
```

**Observação:** os modelos abaixo usam **análise por caso completo** (listwise deletion), que é o comportamento padrão do `glm()`/`lm()` quando há dados faltantes nas variáveis do modelo.

## Codificação de variáveis categóricas (referências)

As variáveis categóricas entram como fatores. A **categoria de referência** (baseline) é o **primeiro nível** do fator (conforme `levels()`), a menos que seja explicitamente reordenado.

```{r}
categoricas <- c(
    "sexo",
    "lenke",
    "risser",
    "flexibilidade",
    "regiao_cobb_inicial",
    "escoliometro_maior_10_graus",
    "lenke_curvatura",
    "risser_agrupado",
    "cifose_categ",
    "lordose_categ"
)
map_dfr(categoricas, function(v) {
    tibble(
        variavel = v,
        niveis = paste(levels(df[[v]]), collapse = " | ")
    )
}) |>
    print(n = Inf)
```

<br>
<br>
<br>

# Análise descritiva

## Variáveis de entrada do modelo

Variáveis coletadas na linha de base.

```{r}
df |>
    gtsummary::tbl_summary(
        include = c(
            # numericas
            idade,
            altura,
            peso,
            imc,
            cifose_toracica,
            lordose_lombar,
            dif_colete,
            correcao_colete,

            # categoricas
            sexo,
            lenke,
            risser,
            flexibilidade,
            regiao_cobb_inicial,
            escoliometro_maior_10_graus,
            lenke_curvatura,
            risser_agrupado,
            cifose_categ,
            lordose_categ,
        ),
        type = list(
            idade ~ "continuous"
        ),
        statistic = list(
            gtsummary::all_continuous() ~ "{mean} ({sd})",
            gtsummary::all_categorical() ~ "{n} ({p}%)"
        )
    )

```


## Desfecho principal

- Maior curva na linha de base e em 6 meses.    
- Delta: maior curva 6 meses - maior curva baseline.    
- Delta categórica: delta melhor em 5 graus ou mais (MCID).    


```{r}
df |>
    gtsummary::tbl_summary(
        include = c(
            cobb_inicial_maior,
            maior_curva_6_meses,
            delta,
            delta_cat_f
        ),
        type = list(
            delta_cat_f ~ "categorical"
        ),
        statistic = list(
            gtsummary::all_continuous() ~ "{mean} ({sd})",
            gtsummary::all_categorical() ~ "{n} ({p}%)"
        )
    )

```


## Distribuição do desfecho principal
```{r}
df |>
    ggplot(aes(x = "", y = delta)) +
    PupillometryR::geom_flat_violin(
        position = position_nudge(x = .2),
        # fill = "steelblue",
        alpha = 0.7
    ) +
    labs(
        title = "Distribution of the outcome (delta)",
        x = "",
        y = "delta (degrees)"
    ) +
    geom_point(position = position_jitter(w = .15)) +
    geom_boxplot(
        width = .25,
        alpha = 0.7,
        outlier.shape = NA
    ) +
    coord_flip() +
    theme(
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank()
    )
```

```{r}
df |>
    ggplot(aes(sample = delta)) +
    qqplotr::stat_qq_band(alpha = 0.2) +
    qqplotr::stat_qq_line() +
    qqplotr::stat_qq_point() +
    labs(
        title = "Outcome QQ-plot (delta)",
        x = "Theoretical quantiles",
        y = "Sample quantiles"
    )
```

<br>
<br>
<br>


# Modelagem

## Combinação de variáveis

### Variáveis originais

Incluindo:

- idade 
- imc   
- cifose_toracica    
- lordose_lombar    
- dif_colete       
- sexo   
- lenke    
- risser    
- flexibilidade    
- escoliometro_maior_10_graus    


#### Modelo de regressão linear

Este modelo estima associações ajustadas com o desfecho contínuo $\Delta$ (maior curva em 6 meses − baseline, em graus).


```{r}
model_lin <- lm(
    delta ~
        # numericas
        idade +
        # altura +
        # peso +
        imc +
        cifose_toracica +
        lordose_lombar +
        dif_colete +
        # correcao_colete +

        # categoricas
        sexo +
        lenke +
        risser +
        flexibilidade +
        # regiao_cobb_inicial +
        escoliometro_maior_10_graus
    # lenke_curvatura +
    # risser_agrupado +
    # cifose_categ +
    # lordose_categ,
    ,
    data = df
)
```



##### Parâmetros do modelo

```{r}
model_lin |>
    gtsummary::tbl_regression(conf.level = 0.95) |>
    # gtsummary::add_global_p() |>
    gtsummary::bold_p() |>
    gtsummary::bold_labels() |>
    gtsummary::italicize_levels()
```



##### Heteroscedasticidade

Verificação de heteroscedasticidade entre as variáveis independentes (Breusch-Pagan test).

```{r}
performance::check_heteroscedasticity(model_lin)
performance::check_heteroscedasticity(model_lin) |> plot()
```



##### Normalidade dos resíduos

```{r}
performance::check_residuals(model_lin)
performance::check_residuals(model_lin) |> plot()
```

##### Autocorrelação dos resíduos

Independência dos resíduos (Durbin-Watson test).

```{r}
performance::check_autocorrelation(model_lin)
```

##### Verificações preditivas posteriores

Simulação de dados replicados sob o modelo ajustado e posterior comparação com os dados observados.

```{r}
performance::check_predictions(model_lin) |> plot()
```


##### Colinearidade

Verificação de colinearidade entre as variáveis independentes (_Variance Inflation Factor_).
Valores maiores que 10 indicam colinearidade entre as variáveis.

```{r}
performance::check_collinearity(model_lin) |>
    arrange(desc(VIF)) |>
    select(Term, VIF, VIF_CI_low, VIF_CI_high) |>
    performance::print_html()

performance::check_collinearity(model_lin) |> plot()
```

##### Outliers

```{r}
performance::check_outliers(model_lin)
performance::check_outliers(model_lin) |> plot()
```



##### Coeficiente de determinação

$R^2$.
```{r}
# Qualidade do ajuste
performance::r2(model_lin)
```

##### Tamanho amostral efetivo (casos completos)

```{r}
tibble(n_modelo = nobs(model_lin))
```

<br>
<br>
<br>

#### Modelo de regressão logística

Este modelo estima associações ajustadas com a **chance de melhora (MCID)**, definida como $\Delta \le -5°$.


```{r}
model_bin <- glm(
    delta_cat ~
        # numericas
        idade +
        # altura +
        # peso +
        imc +
        cifose_toracica +
        lordose_lombar +
        dif_colete +
        # correcao_colete +

        # categoricas
        sexo +
        lenke +
        risser +
        flexibilidade +
        # regiao_cobb_inicial +
        escoliometro_maior_10_graus
    # lenke_curvatura +
    # risser_agrupado +
    # cifose_categ +
    # lordose_categ,
    ,
    data = df,
    family = "binomial"
)
```


##### Parâmetros do modelo

Parâmetros do modelo de regressão logística. Resposta em _Odds Ratio_.

```{r}
model_bin |>
    gtsummary::tbl_regression(exponentiate = TRUE, conf.level = 0.95) |>
    # gtsummary::add_global_p() |>
    gtsummary::bold_p() |>
    gtsummary::bold_labels() |>
    gtsummary::italicize_levels()
```


##### Resíduos binarizados

```{r}
performance::binned_residuals(model_bin) |> plot()
```

##### Autocorrelação dos resíduos

Independência dos resíduos (Durbin-Watson test).

```{r}
performance::check_autocorrelation(model_bin)
```


##### Verificações preditivas posteriores

Simulação de dados replicados sob o modelo ajustado e posterior comparação com os dados observados.

```{r}
performance::check_predictions(model_bin) |> plot()
```


##### Qualidade do ajuste do modelo

Teste de Hosmer-Lemeshow para avaliar a qualidade do ajuste de modelos binomiais. P-valor < 0.05 indica que o modelo não ajusta bem os dados.

```{r}
performance::performance_hosmer(model_bin)
```


##### Colinearidade

Verificação de colinearidade entre as variáveis independentes (_Variance Inflation Factor_).
Valores maiores que 10 indicam colinearidade entre as variáveis.

```{r}
performance::check_collinearity(model_bin) |>
    arrange(desc(VIF)) |>
    select(Term, VIF, VIF_CI_low, VIF_CI_high) |>
    performance::print_html()

performance::check_collinearity(model_bin) |> plot()
```

##### Outliers

```{r}
performance::check_outliers(model_bin)
performance::check_outliers(model_bin) |> plot()
```


##### Coeficiente de determinação (Tjur)

Coeficiente de determinação de Tjur ($R^2_{Tjur}$). Teste específico para modelos binomiais.

```{r}
performance::r2(model_bin)
```

##### Tamanho amostral efetivo (casos completos)

```{r}
mf_bin <- model.frame(model_bin)
bin_n <- nrow(mf_bin)
bin_events <- sum(mf_bin[[1]] == 1, na.rm = TRUE)
bin_nonevents <- sum(mf_bin[[1]] == 0, na.rm = TRUE)
tibble(
    n_modelo = bin_n,
    eventos_mcid = bin_events,
    nao_eventos = bin_nonevents
)
```

<br>
<br>
<br>


#### CART (árvore de decisão) para MCID (delta_cat)

##### Racional teórico

Um modelo CART (Classification and Regression Tree) é útil aqui porque:

- **Não linearidade**: identifica automaticamente limiares (pontos de corte) em preditores contínuos.
- **Interações**: a sequência de divisões (splits) representa interações condicionais sem precisar pre-especificar termos de interação.
- **Interpretabilidade**: gera regras do tipo "se... então...", úteis para comunicação clínica e geração de hipóteses.

**Limitações importantes:** árvores isoladas tendem a ter alta variância e podem superajustar. Por isso, esta seção usa **validação cruzada (CV)** e **tuning/poda** para controlar complexidade e reporta desempenho **interno** (sem validação externa).

##### Setup e preparação dos dados

```{r}
#| label: cart-setup_a

library(tidymodels)
library(rpart.plot)
library(vip)

set.seed(123)

# Desfecho como fator: "melhora" (evento) vs "nao_melhora"
df_cart <- df |>
    mutate(
        delta_cat_cart = factor(
            delta_cat,
            levels = c(0, 1),
            labels = c("nao_melhora", "melhora")
        )
    ) |>
    select(
        delta_cat_cart,
        # numericas
        idade,
        # altura,
        # peso,
        imc,
        cifose_toracica,
        lordose_lombar,
        dif_colete,
        # correcao_colete,

        # categoricas
        sexo,
        lenke,
        risser,
        flexibilidade,
        # regiao_cobb_inicial,
        escoliometro_maior_10_graus,
        # lenke_curvatura,
        # risser_agrupado,
        # cifose_categ,
        # lordose_categ,
    )

# Verificar niveis (evento = "melhora", segundo nivel)
levels(df_cart$delta_cat_cart)
```

##### Recipe (pre-processamento)

O pre-processamento é feito **dentro do resampling** (evita leakage):

- `step_zv()`: remove variáveis com variância zero
- `step_unknown()` + `step_novel()`: robustez a níveis novos/raros durante CV
- `step_impute_median()` + `step_impute_mode()`: imputação de missings

```{r}
#| label: cart-recipe_a

cart_rec <- recipe(delta_cat_cart ~ ., data = df_cart) |>
    step_zv(all_predictors()) |>
    step_unknown(all_nominal_predictors()) |>
    step_novel(all_nominal_predictors()) |>
    step_impute_median(all_numeric_predictors()) |>
    step_impute_mode(all_nominal_predictors())

cart_rec
```

##### Modelo e hiperparâmetros

Hiperparâmetros a serem tunados:

- **`cost_complexity` (cp)**: controla poda/complexidade; valores maiores = árvores menores.
- **`tree_depth`**: limita profundidade (proxy do grau de interações).
- **`min_n`**: mínimo de observações em no terminal; evita regras baseadas em poucos pacientes.

```{r}
#| label: cart-model_a

cart_spec <- decision_tree(
    cost_complexity = tune(),
    tree_depth = tune(),
    min_n = tune()
) |>
    set_engine("rpart") |>
    set_mode("classification")

cart_wf <- workflow() |>
    add_recipe(cart_rec) |>
    add_model(cart_spec)

cart_wf
```

##### Validação cruzada e tuning

Usamos **CV estratificada repetida** (10-fold, 5 repetições) para estimar desempenho e selecionar hiperparâmetros.

```{r}
#| label: cart-cv-tuning_a

set.seed(123)
folds <- vfold_cv(df_cart, v = 10, repeats = 5, strata = delta_cat_cart)

# Metricas de interesse
metricas <- metric_set(roc_auc, accuracy, sens, spec)

# Grid de hiperparametros
set.seed(123)
cart_grid <- grid_latin_hypercube(
    cost_complexity(range = c(-5, -2)),
    tree_depth(range = c(4L, 10L)),
    min_n(range = c(5L, 20L)),
    size = 30
)

# Tuning
set.seed(123)
cart_tuned <- tune_grid(
    cart_wf,
    resamples = folds,
    grid = cart_grid,
    metrics = metricas,
    control = control_grid(save_pred = TRUE)
)
```

##### Melhores hiperparâmetros

Selecionamos pelo **maior AUC ROC medio** na CV:

```{r}
#| label: cart-best-params_a

# Top 10 combinacoes por AUC
cart_tuned |>
    collect_metrics() |>
    filter(.metric == "roc_auc") |>
    arrange(desc(mean)) |>
    slice_head(n = 10)

# Melhor combinacao
best_params <- cart_tuned |>
    select_best(metric = "roc_auc")

best_params
```

##### Desempenho final (CV)

Avaliamos o modelo finalizado com os melhores hiperparâmetros:

```{r}
#| label: cart-final-metrics_a

cart_final_wf <- finalize_workflow(cart_wf, best_params)

set.seed(123)
cart_res <- fit_resamples(
    cart_final_wf,
    resamples = folds,
    metrics = metricas,
    control = control_resamples(save_pred = TRUE)
)

# Metricas agregadas (media e SD)
cart_metrics <- cart_res |>
    collect_metrics() |>
    select(.metric, mean, std_err, n) |>
    mutate(
        ci_lower = mean - 1.96 * std_err,
        ci_upper = mean + 1.96 * std_err
    )

cart_metrics
```

##### Métricas por fold (dispersão)

Visualização da incerteza nas estimativas de desempenho:

```{r}
#| label: cart-metrics-boxplot_a
#| fig-width: 8
#| fig-height: 5

cart_res |>
    collect_metrics(summarize = FALSE) |>
    ggplot(aes(x = .metric, y = .estimate, fill = .metric)) +
    geom_boxplot(alpha = 0.7, show.legend = FALSE) +
    geom_jitter(width = 0.1, alpha = 0.3, size = 1) +
    scale_fill_brewer(palette = "Set2") +
    labs(
        title = "Distribution of metrics by fold (CV repeated)",
        subtitle = "10-fold CV x 5 repetitions = 50 estimates per metric",
        x = "Metric",
        y = "Value"
    ) +
    theme_minimal(base_size = 12) +
    theme(
        plot.title = element_text(face = "bold"),
        axis.text.x = element_text(angle = 0)
    )
```

##### Matriz de confusão agregada (normalizada)

```{r}
#| label: cart-confusion-matrix_a
#| fig-width: 6
#| fig-height: 5

# Predicoes agregadas de todos os folds
preds_all <- cart_res |>
    collect_predictions()

# Matriz de confusao
conf_mat_data <- preds_all |>
    conf_mat(truth = delta_cat_cart, estimate = .pred_class)

# Normalizar por linha (proporcao por classe verdadeira)
conf_mat_tbl <- conf_mat_data$table |>
    as.data.frame() |>
    group_by(Truth) |>
    mutate(
        prop = Freq / sum(Freq),
        label = scales::percent(prop, accuracy = 0.1)
    ) |>
    ungroup()

# Visualizacao heatmap normalizado
ggplot(conf_mat_tbl, aes(x = Prediction, y = Truth, fill = prop)) +
    geom_tile(color = "white", linewidth = 1) +
    geom_text(aes(label = label), size = 5, fontface = "bold") +
    scale_fill_gradient(
        low = "white",
        high = "steelblue",
        labels = scales::percent,
        name = "Proporcao"
    ) +
    scale_y_discrete(limits = rev) +
    labs(
        title = "Confucion Matrix",
        subtitle = "Proportion by true class (rows sum to 100%)",
        x = "Prediction",
        y = "True"
    ) +
    theme_minimal(base_size = 12) +
    theme(
        plot.title = element_text(face = "bold"),
        panel.grid = element_blank()
    )
```

##### Árvore final

Ajustamos o modelo final no dataset completo para visualização e interpretação:

```{r}
#| label: cart-final-tree_a
#| fig-width: 10
#| fig-height: 8

cart_fit_full <- fit(cart_final_wf, data = df_cart)
cart_rpart <- extract_fit_engine(cart_fit_full)

# Plot da arvore com rpart.plot
rpart.plot(
    cart_rpart,
    type = 4,
    extra = 104,
    under = TRUE,
    fallen.leaves = TRUE,
    roundint = FALSE,
    box.palette = "BuGn",
    shadow.col = "gray",
    main = "Decision Tree for MCID (delta <= -5 degrees)"
)
```

##### Importância de variáveis

```{r}
#| label: cart-vip_a
#| fig-width: 8
#| fig-height: 6

# Grafico de importancia com vip
cart_fit_full |>
    extract_fit_parsnip() |>
    vip(
        num_features = 15,
        geom = "col",
        aesthetics = list(fill = "steelblue", alpha = 0.8)
    ) +
    labs(
        title = "Variable Importance (CART)",
        subtitle = "Based on impurity reduction (Gini)",
        x = "Importance",
        y = "Variable"
    ) +
    theme_minimal(base_size = 12) +
    theme(plot.title = element_text(face = "bold"))
```

##### Tabela de folhas (grupos de predicao)

Esta tabela mostra os **nós terminais** (folhas) da árvore, com as regras que definem cada grupo, o tamanho do grupo e a proporção de melhora:

```{r}
#| label: cart-leaves-table_a

# Extrair informacoes dos nos terminais
frame <- cart_rpart$frame
leaves_idx <- which(frame$var == "<leaf>")

# Funcao para extrair regras de cada no
get_path_rules <- function(tree, node_id) {
    path <- rpart::path.rpart(tree, nodes = node_id, print.it = FALSE)
    rules <- path[[1]][-1] # remover "root"
    if (length(rules) == 0) {
        return("(raiz)")
    }
    paste(rules, collapse = " E ")
}

# Construir tabela de folhas
leaves_tbl <- tibble(
    no = as.integer(rownames(frame)[leaves_idx]),
    n = frame$n[leaves_idx],
    n_melhora = frame$n[leaves_idx] * frame$yval2[leaves_idx, 5],
    n_nao_melhora = frame$n[leaves_idx] * frame$yval2[leaves_idx, 4],
    prop_melhora = frame$yval2[leaves_idx, 5],
    predicao = ifelse(frame$yval[leaves_idx] == 2, "melhora", "nao_melhora")
) |>
    rowwise() |>
    mutate(regras = get_path_rules(cart_rpart, no)) |>
    ungroup() |>
    mutate(
        prop_melhora_pct = scales::percent(prop_melhora, accuracy = 0.1),
        grupo = paste0("Grupo ", row_number())
    ) |>
    select(grupo, predicao, n, prop_melhora_pct, regras) |>
    arrange(desc(predicao), desc(n))

leaves_tbl |>
    rename(
        Grupo = grupo,
        Predicao = predicao,
        N = n,
        `% Melhora` = prop_melhora_pct,
        Regras = regras
    ) |>
    knitr::kable(align = c("l", "l", "r", "r", "l"))
```

##### Curva ROC

```{r}
#| label: cart-roc-curve_a
#| fig-width: 7
#| fig-height: 6

# Curva ROC a partir das predicoes CV
roc_data <- preds_all |>
    roc_curve(truth = delta_cat_cart, .pred_melhora, event_level = "second")

# AUC para o titulo
auc_val <- preds_all |>
    roc_auc(truth = delta_cat_cart, .pred_melhora, event_level = "second") |>
    pull(.estimate)

ggplot(roc_data, aes(x = 1 - specificity, y = sensitivity)) +
    geom_path(linewidth = 1.2, color = "steelblue") +
    geom_abline(linetype = "dashed", color = "gray50") +
    geom_ribbon(
        aes(ymin = 0, ymax = sensitivity),
        alpha = 0.1,
        fill = "steelblue"
    ) +
    annotate(
        "text",
        x = 0.6,
        y = 0.3,
        label = paste0("AUC = ", round(auc_val, 3)),
        size = 5,
        fontface = "bold"
    ) +
    labs(
        title = "ROC Curve (CV)",
        subtitle = "Based on aggregated predictions from all folds",
        x = "1 - Specificity (False Positive Rate)",
        y = "Sensitivity (True Positive Rate)"
    ) +
    coord_equal() +
    theme_minimal(base_size = 12) +
    theme(plot.title = element_text(face = "bold"))
```

##### Interpretação

**Como ler a árvore:**

- Cada **nó interno** representa uma condição (split) sobre uma variável.
- Cada **caminho** da raiz ate um nó terminal representa uma **regra** de classificação.
- A **sequencia de splits** indica **interações condicionais**: um split so importa dentro da região definida por splits anteriores.
- Os **limiares** (pontos de corte) sugerem **não-linearidades** nos efeitos.

**Como ler a importância:**

- Variáveis com maior importância contribuem mais para a redução de impureza (Gini) nos splits.
- Isso **não implica causalidade**, apenas relevância preditiva no contexto do modelo.

**Limitações:**

- Desempenho reportado e **interno** (CV), sem validação externa.
- Árvores são **instáveis**: pequenas mudanças nos dados podem alterar a estrutura.
- Usar como **ferramenta exploratória** complementar aos modelos inferenciais (linear/logístico).


<br>
<br>
<br>
<br>
<br>

### Variáveis discretizadas

Incluindo:

- idade 
- imc   
- cifose_toracica_categ    
- lordose_lombar_categ    
- dif_colete       
- sexo   
- lenke_curvatura    
- risser_agrupado    
- flexibilidade    
- escoliometro_maior_10_graus    


#### Modelo de regressão linear

Este modelo estima associações ajustadas com o desfecho contínuo $\Delta$ (maior curva em 6 meses − baseline, em graus).


```{r}
model_lin <- lm(
    delta ~
        # numericas
        idade +
        # altura +
        # peso +
        imc +
        # cifose_toracica +
        # lordose_lombar +
        dif_colete +
        # correcao_colete +

        # categoricas
        sexo +
        # lenke +
        # risser +
        flexibilidade +
        # regiao_cobb_inicial +
        escoliometro_maior_10_graus +
        lenke_curvatura +
        risser_agrupado +
        cifose_categ +
        lordose_categ,
    data = df
)
```



##### Parâmetros do modelo

```{r}
model_lin |>
    gtsummary::tbl_regression(conf.level = 0.95) |>
    # gtsummary::add_global_p() |>
    gtsummary::bold_p() |>
    gtsummary::bold_labels() |>
    gtsummary::italicize_levels()
```



##### Heteroscedasticidade

Verificação de heteroscedasticidade entre as variáveis independentes (Breusch-Pagan test).

```{r}
performance::check_heteroscedasticity(model_lin)
performance::check_heteroscedasticity(model_lin) |> plot()
```




##### Normalidade dos resíduos

```{r}
performance::check_residuals(model_lin)
performance::check_residuals(model_lin) |> plot()
```

##### Autocorrelação dos resíduos

Independência dos resíduos (Durbin-Watson test).

```{r}
performance::check_autocorrelation(model_lin)
```


##### Verificações preditivas posteriores

Simulação de dados replicados sob o modelo ajustado e posterior comparação com os dados observados.

```{r}
performance::check_predictions(model_lin) |> plot()
```


##### Colinearidade

Verificação de colinearidade entre as variáveis independentes (_Variance Inflation Factor_).
Valores maiores que 10 indicam colinearidade entre as variáveis.

```{r}
performance::check_collinearity(model_lin) |>
    arrange(desc(VIF)) |>
    select(Term, VIF, VIF_CI_low, VIF_CI_high) |>
    performance::print_html()

performance::check_collinearity(model_lin) |> plot()
```


##### Outliers

```{r}
performance::check_outliers(model_lin)
performance::check_outliers(model_lin) |> plot()
```


##### Coeficiente de determinação

$R^2$.
```{r}
# Qualidade do ajuste
performance::r2(model_lin)
```

##### Tamanho amostral efetivo (casos completos)

```{r}
tibble(n_modelo = nobs(model_lin))
```

<br>
<br>
<br>

#### Modelo de regressão logística

Este modelo estima associações ajustadas com a **chance de melhora (MCID)**, definida como $\Delta \le -5°$.


```{r}
model_bin <- glm(
    delta_cat ~
        # numericas
        idade +
        # altura +
        # peso +
        imc +
        # cifose_toracica +
        # lordose_lombar +
        dif_colete +
        # correcao_colete +

        # categoricas
        sexo +
        # lenke +
        # risser +
        flexibilidade +
        # regiao_cobb_inicial +
        escoliometro_maior_10_graus +
        lenke_curvatura +
        risser_agrupado +
        cifose_categ +
        lordose_categ,
    data = df,
    family = "binomial"
)
```


##### Parâmetros do modelo

Parâmetros do modelo de regressão logística. Resposta em _Odds Ratio_.

```{r}
model_bin |>
    gtsummary::tbl_regression(exponentiate = TRUE, conf.level = 0.95) |>
    # gtsummary::add_global_p() |>
    gtsummary::bold_p() |>
    gtsummary::bold_labels() |>
    gtsummary::italicize_levels()
```


##### Resíduos binarizados

```{r}
performance::binned_residuals(model_bin) |> plot()
```

##### Autocorrelação dos resíduos

Independência dos resíduos (Durbin-Watson test).

```{r}
performance::check_autocorrelation(model_bin)
```

##### Verificações preditivas posteriores

Simulação de dados replicados sob o modelo ajustado e posterior comparação com os dados observados.

```{r}
performance::check_predictions(model_bin) |> plot()
```


##### Qualidade do ajuste do modelo

Teste de Hosmer-Lemeshow para avaliar a qualidade do ajuste de modelos binomiais. P-valor < 0.05 indica que o modelo não ajusta bem os dados.

```{r}
performance::performance_hosmer(model_bin)
```


##### Colinearidade

Verificação de colinearidade entre as variáveis independentes (_Variance Inflation Factor_).
Valores maiores que 10 indicam colinearidade entre as variáveis.

```{r}
performance::check_collinearity(model_bin) |>
    arrange(desc(VIF)) |>
    select(Term, VIF, VIF_CI_low, VIF_CI_high) |>
    performance::print_html()

performance::check_collinearity(model_bin) |> plot()
```


##### Outliers

```{r}
performance::check_outliers(model_bin)
performance::check_outliers(model_bin) |> plot()
```


##### Coeficiente de determinação (Tjur)

Coeficiente de determinação de Tjur ($R^2_{Tjur}$). Teste específico para modelos binomiais.

```{r}
performance::r2(model_bin)
```

##### Tamanho amostral efetivo (casos completos)

```{r}
mf_bin <- model.frame(model_bin)
bin_n <- nrow(mf_bin)
bin_events <- sum(mf_bin[[1]] == 1, na.rm = TRUE)
bin_nonevents <- sum(mf_bin[[1]] == 0, na.rm = TRUE)
tibble(
    n_modelo = bin_n,
    eventos_mcid = bin_events,
    nao_eventos = bin_nonevents
)
```

<br>
<br>
<br>


#### CART (árvore de decisão) para MCID (delta_cat)

##### Racional teórico

Um modelo CART (Classification and Regression Tree) é útil aqui porque:

- **Não linearidade**: identifica automaticamente limiares (pontos de corte) em preditores contínuos.
- **Interações**: a sequência de divisões (splits) representa interações condicionais sem precisar pre-especificar termos de interação.
- **Interpretabilidade**: gera regras do tipo "se... então...", úteis para comunicação clínica e geração de hipóteses.

**Limitações importantes:** árvores isoladas tendem a ter alta variância e podem superajustar. Por isso, esta seção usa **validação cruzada (CV)** e **tuning/poda** para controlar complexidade e reporta desempenho **interno** (sem validação externa).

##### Setup e preparação dos dados

```{r}
#| label: cart-setup_b

library(tidymodels)
library(rpart.plot)
library(vip)

set.seed(123)

# Desfecho como fator: "melhora" (evento) vs "nao_melhora"
df_cart <- df |>
    mutate(
        delta_cat_cart = factor(
            delta_cat,
            levels = c(0, 1),
            labels = c("nao_melhora", "melhora")
        )
    ) |>
    select(
        delta_cat_cart,
        # numericas
        idade,
        # altura,
        # peso,
        imc,
        # cifose_toracica,
        # lordose_lombar,
        dif_colete,
        # correcao_colete,

        # categoricas
        sexo,
        # lenke,
        # risser,
        flexibilidade,
        # regiao_cobb_inicial,
        escoliometro_maior_10_graus,
        lenke_curvatura,
        risser_agrupado,
        cifose_categ,
        lordose_categ,
    )

# Verificar niveis (evento = "melhora", segundo nivel)
levels(df_cart$delta_cat_cart)
```

##### Recipe (pre-processamento)

O pre-processamento é feito **dentro do resampling** (evita leakage):

- `step_zv()`: remove variáveis com variância zero
- `step_unknown()` + `step_novel()`: robustez a níveis novos/raros durante CV
- `step_impute_median()` + `step_impute_mode()`: imputação de missings

```{r}
#| label: cart-recipe_b

cart_rec <- recipe(delta_cat_cart ~ ., data = df_cart) |>
    step_zv(all_predictors()) |>
    step_unknown(all_nominal_predictors()) |>
    step_novel(all_nominal_predictors()) |>
    step_impute_median(all_numeric_predictors()) |>
    step_impute_mode(all_nominal_predictors())

cart_rec
```

##### Modelo e hiperparâmetros

Hiperparâmetros a serem tunados:

- **`cost_complexity` (cp)**: controla poda/complexidade; valores maiores = árvores menores.
- **`tree_depth`**: limita profundidade (proxy do grau de interações).
- **`min_n`**: mínimo de observações em no terminal; evita regras baseadas em poucos pacientes.

```{r}
#| label: cart-model_b

cart_spec <- decision_tree(
    cost_complexity = tune(),
    tree_depth = tune(),
    min_n = tune()
) |>
    set_engine("rpart") |>
    set_mode("classification")

cart_wf <- workflow() |>
    add_recipe(cart_rec) |>
    add_model(cart_spec)

cart_wf
```

##### Validação cruzada e tuning

Usamos **CV estratificada repetida** (10-fold, 5 repetições) para estimar desempenho e selecionar hiperparâmetros.

```{r}
#| label: cart-cv-tuning_b

set.seed(123)
folds <- vfold_cv(df_cart, v = 10, repeats = 5, strata = delta_cat_cart)

# Metricas de interesse
metricas <- metric_set(roc_auc, accuracy, sens, spec)

# Grid de hiperparametros
set.seed(123)
cart_grid <- grid_latin_hypercube(
    cost_complexity(range = c(-5, -2)),
    tree_depth(range = c(4L, 10L)),
    min_n(range = c(5L, 20L)),
    size = 30
)

# Tuning
set.seed(123)
cart_tuned <- tune_grid(
    cart_wf,
    resamples = folds,
    grid = cart_grid,
    metrics = metricas,
    control = control_grid(save_pred = TRUE)
)
```

##### Melhores hiperparâmetros

Selecionamos pelo **maior AUC ROC medio** na CV:

```{r}
#| label: cart-best-params_b

# Top 10 combinacoes por AUC
cart_tuned |>
    collect_metrics() |>
    filter(.metric == "roc_auc") |>
    arrange(desc(mean)) |>
    slice_head(n = 10)

# Melhor combinacao
best_params <- cart_tuned |>
    select_best(metric = "roc_auc")

best_params
```

##### Desempenho final (CV)

Avaliamos o modelo finalizado com os melhores hiperparâmetros:

```{r}
#| label: cart-final-metrics_b

cart_final_wf <- finalize_workflow(cart_wf, best_params)

set.seed(123)
cart_res <- fit_resamples(
    cart_final_wf,
    resamples = folds,
    metrics = metricas,
    control = control_resamples(save_pred = TRUE)
)

# Metricas agregadas (media e SD)
cart_metrics <- cart_res |>
    collect_metrics() |>
    select(.metric, mean, std_err, n) |>
    mutate(
        ci_lower = mean - 1.96 * std_err,
        ci_upper = mean + 1.96 * std_err
    )

cart_metrics
```

##### Métricas por fold (dispersão)

Visualização da incerteza nas estimativas de desempenho:

```{r}
#| label: cart-metrics-boxplot_b
#| fig-width: 8
#| fig-height: 5

cart_res |>
    collect_metrics(summarize = FALSE) |>
    ggplot(aes(x = .metric, y = .estimate, fill = .metric)) +
    geom_boxplot(alpha = 0.7, show.legend = FALSE) +
    geom_jitter(width = 0.1, alpha = 0.3, size = 1) +
    scale_fill_brewer(palette = "Set2") +
    labs(
        title = "Distribution of metrics by fold (CV repeated)",
        subtitle = "10-fold CV x 5 repetitions = 50 estimates per metric",
        x = "Metric",
        y = "Value"
    ) +
    theme_minimal(base_size = 12) +
    theme(
        plot.title = element_text(face = "bold"),
        axis.text.x = element_text(angle = 0)
    )
```

##### Matriz de confusão agregada (normalizada)

```{r}
#| label: cart-confusion-matrix_b
#| fig-width: 6
#| fig-height: 5

# Predicoes agregadas de todos os folds
preds_all <- cart_res |>
    collect_predictions()

# Matriz de confusao
conf_mat_data <- preds_all |>
    conf_mat(truth = delta_cat_cart, estimate = .pred_class)

# Normalizar por linha (proporcao por classe verdadeira)
conf_mat_tbl <- conf_mat_data$table |>
    as.data.frame() |>
    group_by(Truth) |>
    mutate(
        prop = Freq / sum(Freq),
        label = scales::percent(prop, accuracy = 0.1)
    ) |>
    ungroup()

# Visualizacao heatmap normalizado
ggplot(conf_mat_tbl, aes(x = Prediction, y = Truth, fill = prop)) +
    geom_tile(color = "white", linewidth = 1) +
    geom_text(aes(label = label), size = 5, fontface = "bold") +
    scale_fill_gradient(
        low = "white",
        high = "steelblue",
        labels = scales::percent,
        name = "Proporcao"
    ) +
    scale_y_discrete(limits = rev) +
    labs(
        title = "Confucion Matrix",
        subtitle = "Proportion by true class (rows sum to 100%)",
        x = "Prediction",
        y = "True"
    ) +
    theme_minimal(base_size = 12) +
    theme(
        plot.title = element_text(face = "bold"),
        panel.grid = element_blank()
    )
```

##### Árvore final

Ajustamos o modelo final no dataset completo para visualização e interpretação:

```{r}
#| label: cart-final-tree_b
#| fig-width: 10
#| fig-height: 8

cart_fit_full <- fit(cart_final_wf, data = df_cart)
cart_rpart <- extract_fit_engine(cart_fit_full)

# Plot da arvore com rpart.plot
rpart.plot(
    cart_rpart,
    type = 4,
    extra = 104,
    under = TRUE,
    fallen.leaves = TRUE,
    roundint = FALSE,
    box.palette = "BuGn",
    shadow.col = "gray",
    main = "Decision Tree for MCID (delta <= -5 degrees)"
)
```

##### Importância de variáveis

```{r}
#| label: cart-vip_b
#| fig-width: 8
#| fig-height: 6

# Grafico de importancia com vip
cart_fit_full |>
    extract_fit_parsnip() |>
    vip(
        num_features = 15,
        geom = "col",
        aesthetics = list(fill = "steelblue", alpha = 0.8)
    ) +
    labs(
        title = "Variable Importance (CART)",
        subtitle = "Based on impurity reduction (Gini)",
        x = "Importance",
        y = "Variable"
    ) +
    theme_minimal(base_size = 12) +
    theme(plot.title = element_text(face = "bold"))
```

##### Tabela de folhas (grupos de predicao)

Esta tabela mostra os **nós terminais** (folhas) da árvore, com as regras que definem cada grupo, o tamanho do grupo e a proporção de melhora:

```{r}
#| label: cart-leaves-table_b

# Extrair informacoes dos nos terminais
frame <- cart_rpart$frame
leaves_idx <- which(frame$var == "<leaf>")

# Funcao para extrair regras de cada no
get_path_rules <- function(tree, node_id) {
    path <- rpart::path.rpart(tree, nodes = node_id, print.it = FALSE)
    rules <- path[[1]][-1] # remover "root"
    if (length(rules) == 0) {
        return("(raiz)")
    }
    paste(rules, collapse = " E ")
}

# Construir tabela de folhas
leaves_tbl <- tibble(
    no = as.integer(rownames(frame)[leaves_idx]),
    n = frame$n[leaves_idx],
    n_melhora = frame$n[leaves_idx] * frame$yval2[leaves_idx, 5],
    n_nao_melhora = frame$n[leaves_idx] * frame$yval2[leaves_idx, 4],
    prop_melhora = frame$yval2[leaves_idx, 5],
    predicao = ifelse(frame$yval[leaves_idx] == 2, "melhora", "nao_melhora")
) |>
    rowwise() |>
    mutate(regras = get_path_rules(cart_rpart, no)) |>
    ungroup() |>
    mutate(
        prop_melhora_pct = scales::percent(prop_melhora, accuracy = 0.1),
        grupo = paste0("Grupo ", row_number())
    ) |>
    select(grupo, predicao, n, prop_melhora_pct, regras) |>
    arrange(desc(predicao), desc(n))

leaves_tbl |>
    rename(
        Grupo = grupo,
        Predicao = predicao,
        N = n,
        `% Melhora` = prop_melhora_pct,
        Regras = regras
    ) |>
    knitr::kable(align = c("l", "l", "r", "r", "l"))
```

##### Curva ROC

```{r}
#| label: cart-roc-curve_b
#| fig-width: 7
#| fig-height: 6

# Curva ROC a partir das predicoes CV
roc_data <- preds_all |>
    roc_curve(truth = delta_cat_cart, .pred_melhora, event_level = "second")

# AUC para o titulo
auc_val <- preds_all |>
    roc_auc(truth = delta_cat_cart, .pred_melhora, event_level = "second") |>
    pull(.estimate)

ggplot(roc_data, aes(x = 1 - specificity, y = sensitivity)) +
    geom_path(linewidth = 1.2, color = "steelblue") +
    geom_abline(linetype = "dashed", color = "gray50") +
    geom_ribbon(
        aes(ymin = 0, ymax = sensitivity),
        alpha = 0.1,
        fill = "steelblue"
    ) +
    annotate(
        "text",
        x = 0.6,
        y = 0.3,
        label = paste0("AUC = ", round(auc_val, 3)),
        size = 5,
        fontface = "bold"
    ) +
    labs(
        title = "ROC Curve (CV)",
        subtitle = "Based on aggregated predictions from all folds",
        x = "1 - Specificity (False Positive Rate)",
        y = "Sensitivity (True Positive Rate)"
    ) +
    coord_equal() +
    theme_minimal(base_size = 12) +
    theme(plot.title = element_text(face = "bold"))
```

##### Interpretação

**Como ler a árvore:**

- Cada **nó interno** representa uma condição (split) sobre uma variável.
- Cada **caminho** da raiz ate um nó terminal representa uma **regra** de classificação.
- A **sequencia de splits** indica **interações condicionais**: um split so importa dentro da região definida por splits anteriores.
- Os **limiares** (pontos de corte) sugerem **não-linearidades** nos efeitos.

**Como ler a importância:**

- Variáveis com maior importância contribuem mais para a redução de impureza (Gini) nos splits.
- Isso **não implica causalidade**, apenas relevância preditiva no contexto do modelo.

**Limitações:**

- Desempenho reportado e **interno** (CV), sem validação externa.
- Árvores são **instáveis**: pequenas mudanças nos dados podem alterar a estrutura.
- Usar como **ferramenta exploratória** complementar aos modelos inferenciais (linear/logístico).

