---
title: "Scoliosis Model"
author: "Caio Vallio"
abstract: |
  **Contexto:** A escoliose idiopática do adolescente pode apresentar resposta clínica variável a intervenções conservadoras.  
  **Objetivo:** Explorar associações entre características basais e melhora radiográfica em 6 meses.  
  **Métodos:** Estudo observacional com análise exploratória e inferencial. O desfecho contínuo foi $\Delta$ (maior curva em 6 meses − baseline, em graus). O desfecho binário (MCID) foi melhora definida como $\Delta \le -5°$. Ajustamos um modelo linear para $\Delta$ e um modelo logístico para o MCID, reportando estimativas com IC95% e verificações de adequação dos modelos.  
date: last-modified
format: 
  html:
    self-contained: true
    df-print: paged
    toc: true 
    toc-depth: 5
    number-sections: true
    number-depth: 5
    code-fold: true
execute: 
  echo: true
  warning: false
  message: false
  error: false
  freeze: auto
lang: pt-BR
#bibliography: references.bib
---

## Como reproduzir

- O arquivo de dados é lido de `data/modelagem final.xlsx` (aba `dados`).
- As análises dependem de pacotes R listados no chunk de setup; caso algum pacote esteja ausente, o documento interrompe a execução com uma mensagem explícita.

## Objetivo e delineamento

Este é um relatório **exploratório e inferencial**: o objetivo é **estimar associações ajustadas** entre variáveis basais e a evolução radiográfica em 6 meses.

## Definições de desfecho

- **Desfecho contínuo:** $\Delta$ = (maior curva em 6 meses − maior curva baseline), em graus. Valores mais negativos indicam maior melhora.  
- **Desfecho binário (MCID):** melhora clínica definida como $\Delta \le -5°$ (redução de pelo menos 5 graus).

## Plano de análise estatística

- **Descrição da amostra**: estatísticas descritivas das variáveis basais e do desfecho.
- **Inferência (associações ajustadas)**:
  - **Modelo linear** para $\Delta$ (efeitos como betas, IC95%).
  - **Modelo logístico** para MCID (efeitos como odds ratios, IC95%).
- **Adequação dos modelos**: diagnósticos de assunções (colinearidade, resíduos, heteroscedasticidade quando aplicável) e medidas de qualidade de ajuste (por exemplo, $R^2$).
- **Forma funcional**: para preditores contínuos, assume-se relação aproximadamente linear.

Por se tratar de análise **exploratória**, os resultados devem ser interpretados com cautela, com ênfase em **magnitude/direção** e incerteza (IC95%).


```{r}
## Setup (reprodutibilidade)
pkgs <- c(
    "tidyverse", "gtsummary",
    "readxl", "janitor",
    "performance", "qqplotr", "PupillometryR"
)
missing_pkgs <- pkgs[!vapply(pkgs, requireNamespace, logical(1), quietly = TRUE)]
if (length(missing_pkgs) > 0) {
    stop("Pacotes ausentes: ", paste(missing_pkgs, collapse = ", "))
}
invisible(lapply(pkgs, library, character.only = TRUE))

set.seed(123)
theme_set(theme_minimal())


# read data
df_raw <- readxl::read_excel("data/modelagem final.xlsx", sheet = "dados")

# clean names
df <- df_raw |> janitor::clean_names()

# clean escoliometro
df <- df |>
    mutate(
        escoliometro = pmax(
            escoliomertro_cervical,
            escoliometro_torarica,
            escoliometro_lombar,
            na.rm = TRUE
        )
    ) |>
    mutate(
        regiao = case_when(
            escoliometro == escoliomertro_cervical ~ "cervical",
            escoliometro == escoliometro_torarica ~ "toracica",
            escoliometro == escoliometro_lombar ~ "lombar",
            TRUE ~ NA_character_
        )
    ) |>
    select(
        -escoliomertro_cervical,
        -escoliometro_torarica,
        -escoliometro_lombar
    )

# definicao do desfecho (ver secao acima)
df <- df |>
    mutate(delta = maior_curva_6_meses - maior_curva_baseline) |>
    mutate(delta_cat = if_else(delta <= -5, 1, 0)) |>
    mutate(
        delta_cat_f = factor(
            delta_cat,
            levels = c(0, 1),
            labels = c("Sem melhora (MCID)", "Melhora (MCID)")
        )
    )

# casting de variaveis (garantir tipos adequados no ajuste)
df <- df |>
    mutate(
        idade = as.double(idade),
        lenke = as.factor(lenke),
        risser = as.factor(risser),
        sexo = as.factor(sexo),
        regiao = as.factor(regiao),
        cifose_categ = as.factor(cifose_categ)
    )

```

## Dados faltantes e tamanho amostral

```{r}
missing_tbl <- df |>
    summarise(across(everything(), ~ sum(is.na(.)))) |>
    pivot_longer(everything(), names_to = "variavel", values_to = "n_missing") |>
    mutate(pct_missing = n_missing / nrow(df)) |>
    arrange(desc(pct_missing))

missing_tbl |>
    mutate(pct_missing = scales::percent(pct_missing, accuracy = 0.1)) |>
    print(n = 50)
```

**Observação:** os modelos abaixo usam **análise por caso completo** (listwise deletion), que é o comportamento padrão do `glm()`/`lm()` quando há dados faltantes nas variáveis do modelo.

## Codificação de variáveis categóricas (referências)

As variáveis categóricas entram como fatores. A **categoria de referência** (baseline) é o **primeiro nível** do fator (conforme `levels()`), a menos que seja explicitamente reordenado.

```{r}
categoricas <- c("sexo", "regiao", "lenke", "risser", "cifose_categ")
map_dfr(categoricas, function(v) {
    tibble(
        variavel = v,
        niveis = paste(levels(df[[v]]), collapse = " | ")
    )
}) |>
    print(n = Inf)
```


# Análise descritiva

## Variáveis de entrada do modelo

Variáveis coletadas na linha de base.

```{r}
df |>
    gtsummary::tbl_summary(
        include = c(
            idade,
            altura,
            peso,
            imc,
            cifose_toracica,
            lordose_lombar,
            dif_colete,
            correcao_colete,
            escoliometro,
            inclinacao,
            cifose_categ,
            sexo,
            regiao,
            lenke,
            risser
        ),
        type = list(
            idade ~ "continuous"
        ),
        statistic = list(
            gtsummary::all_continuous() ~ "{mean} ({sd})",
            gtsummary::all_categorical() ~ "{n} ({p}%)"
        )
    )

```


## Desfecho principal

- Maior curva na linha de base e em 6 meses.    
- Delta: maior curva 6 meses - maior curva baseline.    
- Delta categórica: delta melhor em 5 graus ou mais (MCID).    


```{r}
df |>
    gtsummary::tbl_summary(
        include = c(
            maior_curva_baseline,
            maior_curva_6_meses,
            delta,
            delta_cat_f
        ),
        type = list(
            delta_cat_f ~ "categorical"
        ),
        statistic = list(
            gtsummary::all_continuous() ~ "{mean} ({sd})",
            gtsummary::all_categorical() ~ "{n} ({p}%)"
        )
    )

```


## Distribuição do desfecho principal
```{r}
df |>
    ggplot(aes(x = "", y = delta)) +
    PupillometryR::geom_flat_violin(
        position = position_nudge(x = .2),
        # fill = "steelblue",
        alpha = 0.7
    ) +
    labs(
        title = "Distribuicao do desfecho (delta)",
        x = "",
        y = "delta (graus)"
    ) +
    geom_point(position = position_jitter(w = .15)) +
    geom_boxplot(
        width = .25,
        alpha = 0.7,
        outlier.shape = NA
    ) +
    coord_flip() +
    theme(
        axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank()
    )
```

```{r}
df |>
    ggplot(aes(sample = delta)) +
    qqplotr::stat_qq_band(alpha = 0.2) +
    qqplotr::stat_qq_line() +
    qqplotr::stat_qq_point() +
    labs(
        title = "QQ-plot do desfecho (delta)",
        x = "Quantis teoricos",
        y = "Quantis amostrais"
    )
```

# Modelagem

## Modelo de regressão logística

Este modelo estima associações ajustadas com a **chance de melhora (MCID)**, definida como $\Delta \le -5°$.


```{r}
model_bin <- glm(
    delta_cat ~
        idade +
        altura +
        peso +
        # imc +
        cifose_toracica +
        lordose_lombar +
        dif_colete +
        correcao_colete +
        escoliometro +
        inclinacao +
        cifose_categ +
        sexo +
        regiao +
        lenke +
        risser,
    data = df, family = "binomial"
)
```


### Parâmetros do modelo

Parâmetros do modelo de regressão logística. Resposta em _Odds Ratio_.

```{r}
model_bin |>
    gtsummary::tbl_regression(exponentiate = TRUE, conf.level = 0.95) |>
    # gtsummary::add_global_p() |>
    gtsummary::bold_p() |>
    gtsummary::bold_labels() |>
    gtsummary::italicize_levels()
```


### Verificações de adequação do modelo

#### Colinearidade

Verificação de colinearidade entre as variáveis independentes (_Variance Inflation Factor_).
Valores maiores que 10 indicam colinearidade entre as variáveis.

```{r}
performance::check_collinearity(model_bin) |>
    arrange(desc(VIF)) |>
    select(Term, VIF, VIF_CI_low, VIF_CI_high) |>
    performance::print_html()

performance::check_collinearity(model_bin) |> plot()
```

#### Resíduos binarizados

```{r}
performance::binned_residuals(model_bin) |> plot()
```


#### Outliers

```{r}
performance::check_outliers(model_bin)
performance::check_outliers(model_bin) |> plot()
```


#### Valores ajustados (diagnóstico)

```{r}
performance::check_predictions(model_bin) |> plot()
```


#### Resíduos simulados

```{r}
performance::check_residuals(model_bin)
performance::check_residuals(model_bin) |> plot()
```


### Qualidade do ajuste do modelo

Teste de Hosmer-Lemeshow para avaliar a qualidade do ajuste de modelos binomiais. P-valor < 0.05 indica que o modelo não ajusta bem os dados.

```{r}
performance::performance_hosmer(model_bin)
```



#### Coeficiente de determinação (Tjur)

Coeficiente de determinação de Tjur ($R^2_{Tjur}$). Teste específico para modelos binomiais.

```{r}
performance::r2(model_bin)
```

#### Tamanho amostral efetivo (casos completos)

```{r}
mf_bin <- model.frame(model_bin)
bin_n <- nrow(mf_bin)
bin_events <- sum(mf_bin[[1]] == 1, na.rm = TRUE)
bin_nonevents <- sum(mf_bin[[1]] == 0, na.rm = TRUE)
tibble(
    n_modelo = bin_n,
    eventos_mcid = bin_events,
    nao_eventos = bin_nonevents
)
```



## CART (arvore de decisao) para MCID (delta_cat)

### Racional teorico

Um modelo CART (Classification and Regression Tree) e util aqui porque:

- **Nao linearidade**: identifica automaticamente limiares (pontos de corte) em preditores continuos.
- **Interacoes**: a sequencia de divisoes (splits) representa interacoes condicionais sem precisar pre-especificar termos de interacao.
- **Interpretabilidade**: gera regras do tipo "se... entao...", uteis para comunicacao clinica e geracao de hipoteses.

**Limitacoes importantes:** arvores isoladas tendem a ter alta variancia e podem superajustar. Por isso, esta secao usa **validacao cruzada (CV)** e **tuning/poda** para controlar complexidade e reporta desempenho **interno** (sem validacao externa).

### Setup e preparacao dos dados

```{r}
#| label: cart-setup

library(tidymodels)
library(rpart.plot)
library(vip)

set.seed(123)

# Desfecho como fator: "melhora" (evento) vs "nao_melhora"
df_cart <- df |>
    mutate(
        delta_cat_cart = factor(
            delta_cat,
            levels = c(0, 1),
            labels = c("nao_melhora", "melhora")
        )
    ) |>
    select(
        delta_cat_cart,
        idade, altura, peso,
        cifose_toracica, lordose_lombar,
        dif_colete, correcao_colete,
        escoliometro, inclinacao,
        cifose_categ, sexo, regiao, lenke, risser
    )

# Verificar niveis (evento = "melhora", segundo nivel)
levels(df_cart$delta_cat_cart)
```

### Recipe (pre-processamento)

O pre-processamento e feito **dentro do resampling** (evita leakage):

- `step_zv()`: remove variaveis com variancia zero
- `step_unknown()` + `step_novel()`: robustez a niveis novos/raros durante CV
- `step_impute_median()` + `step_impute_mode()`: imputacao de missings

```{r}
#| label: cart-recipe

cart_rec <- recipe(delta_cat_cart ~ ., data = df_cart) |>
    step_zv(all_predictors()) |>
    step_unknown(all_nominal_predictors()) |>
    step_novel(all_nominal_predictors()) |>
    step_impute_median(all_numeric_predictors()) |>
    step_impute_mode(all_nominal_predictors())

cart_rec
```

### Modelo e hiperparametros

Hiperparametros a serem tunados:

- **`cost_complexity` (cp)**: controla poda/complexidade; valores maiores = arvores menores.
- **`tree_depth`**: limita profundidade (proxy do grau de interacoes).
- **`min_n`**: minimo de observacoes em no terminal; evita regras baseadas em poucos pacientes.

```{r}
#| label: cart-model

cart_spec <- decision_tree(
    cost_complexity = tune(),
    tree_depth = tune(),
    min_n = tune()
) |>
    set_engine("rpart") |>
    set_mode("classification")

cart_wf <- workflow() |>
    add_recipe(cart_rec) |>
    add_model(cart_spec)

cart_wf
```

### Validacao cruzada e tuning

Usamos **CV estratificada repetida** (10-fold, 5 repeticoes) para estimar desempenho e selecionar hiperparametros.

```{r}
#| label: cart-cv-tuning

set.seed(123)
folds <- vfold_cv(df_cart, v = 10, repeats = 5, strata = delta_cat_cart)

# Metricas de interesse
metricas <- metric_set(roc_auc, accuracy, sens, spec)

# Grid de hiperparametros
set.seed(123)
cart_grid <- grid_latin_hypercube(
    cost_complexity(range = c(-4, -1)),
    tree_depth(range = c(1L, 6L)),
    min_n(range = c(5L, 30L)),
    size = 30
)

# Tuning
set.seed(123)
cart_tuned <- tune_grid(
    cart_wf,
    resamples = folds,
    grid = cart_grid,
    metrics = metricas,
    control = control_grid(save_pred = TRUE)
)
```

### Melhores hiperparametros

Selecionamos pelo **maior AUC ROC medio** na CV:

```{r}
#| label: cart-best-params

# Top 10 combinacoes por AUC
cart_tuned |>
    collect_metrics() |>
    filter(.metric == "roc_auc") |>
    arrange(desc(mean)) |>
    slice_head(n = 10)

# Melhor combinacao
best_params <- cart_tuned |>
    select_best(metric = "roc_auc")

best_params
```

### Desempenho final (CV)

Avaliamos o modelo finalizado com os melhores hiperparametros:

```{r}
#| label: cart-final-metrics

cart_final_wf <- finalize_workflow(cart_wf, best_params)

set.seed(123)
cart_res <- fit_resamples(
    cart_final_wf,
    resamples = folds,
    metrics = metricas,
    control = control_resamples(save_pred = TRUE)
)

# Metricas agregadas (media e SD)
cart_metrics <- cart_res |>
    collect_metrics() |>
    select(.metric, mean, std_err, n) |>
    mutate(
        ci_lower = mean - 1.96 * std_err,
        ci_upper = mean + 1.96 * std_err
    )

cart_metrics
```

### Metricas por fold (dispersao)

Visualizacao da incerteza nas estimativas de desempenho:

```{r}
#| label: cart-metrics-boxplot
#| fig-width: 8
#| fig-height: 5

cart_res |>
    collect_metrics(summarize = FALSE) |>
    ggplot(aes(x = .metric, y = .estimate, fill = .metric)) +
    geom_boxplot(alpha = 0.7, show.legend = FALSE) +
    geom_jitter(width = 0.1, alpha = 0.3, size = 1) +
    scale_fill_brewer(palette = "Set2") +
    labs(
        title = "Distribuicao das metricas por fold (CV repetida)",
        subtitle = "10-fold CV x 5 repeticoes = 50 estimativas por metrica",
        x = "Metrica",
        y = "Valor"
    ) +
    theme_minimal(base_size = 12) +
    theme(
        plot.title = element_text(face = "bold"),
        axis.text.x = element_text(angle = 0)
    )
```

### Matriz de confusao agregada (normalizada)

```{r}
#| label: cart-confusion-matrix
#| fig-width: 6
#| fig-height: 5

# Predicoes agregadas de todos os folds
preds_all <- cart_res |>
    collect_predictions()

# Matriz de confusao
conf_mat_data <- preds_all |>
    conf_mat(truth = delta_cat_cart, estimate = .pred_class)

# Normalizar por linha (proporcao por classe verdadeira)
conf_mat_tbl <- conf_mat_data$table |>
    as.data.frame() |>
    group_by(Truth) |>
    mutate(
        prop = Freq / sum(Freq),
        label = scales::percent(prop, accuracy = 0.1)
    ) |>
    ungroup()

# Visualizacao heatmap normalizado
ggplot(conf_mat_tbl, aes(x = Prediction, y = Truth, fill = prop)) +
    geom_tile(color = "white", linewidth = 1) +
    geom_text(aes(label = label), size = 5, fontface = "bold") +
    scale_fill_gradient(
        low = "white", 
        high = "steelblue",
        labels = scales::percent,
        name = "Proporcao"
    ) +
    scale_y_discrete(limits = rev) +
    labs(
        title = "Matriz de confusao normalizada (CV)",
        subtitle = "Proporcao por classe verdadeira (linhas somam 100%)",
        x = "Predicao",
        y = "Verdadeiro"
    ) +
    theme_minimal(base_size = 12) +
    theme(
        plot.title = element_text(face = "bold"),
        panel.grid = element_blank()
    )
```

### Arvore final

Ajustamos o modelo final no dataset completo para visualizacao e interpretacao:

```{r}
#| label: cart-final-tree
#| fig-width: 10
#| fig-height: 8

cart_fit_full <- fit(cart_final_wf, data = df_cart)
cart_rpart <- extract_fit_engine(cart_fit_full)

# Plot da arvore com rpart.plot
rpart.plot(
    cart_rpart,
    type = 4,
    extra = 104,
    under = TRUE,
    fallen.leaves = TRUE,
    roundint = FALSE,
    box.palette = "BuGn",
    shadow.col = "gray",
    main = "Arvore de decisao para MCID (delta <= -5 graus)"
)
```

### Importancia de variaveis

```{r}
#| label: cart-vip
#| fig-width: 8
#| fig-height: 6

# Grafico de importancia com vip
cart_fit_full |>
    extract_fit_parsnip() |>
    vip(
        num_features = 15,
        geom = "col",
        aesthetics = list(fill = "steelblue", alpha = 0.8)
    ) +
    labs(
        title = "Importancia das variaveis (CART)",
        subtitle = "Baseado na reducao de impureza (Gini)",
        x = "Importancia",
        y = "Variavel"
    ) +
    theme_minimal(base_size = 12) +
    theme(plot.title = element_text(face = "bold"))
```

### Tabela de folhas (grupos de predicao)

Esta tabela mostra os **nos terminais** (folhas) da arvore, com as regras que definem cada grupo, o tamanho do grupo e a proporcao de melhora:

```{r}
#| label: cart-leaves-table

# Extrair informacoes dos nos terminais
frame <- cart_rpart$frame
leaves_idx <- which(frame$var == "<leaf>")

# Funcao para extrair regras de cada no
get_path_rules <- function(tree, node_id) {
    path <- rpart::path.rpart(tree, nodes = node_id, print.it = FALSE)
    rules <- path[[1]][-1]  # remover "root"
    if (length(rules) == 0) return("(raiz)")
    paste(rules, collapse = " E ")
}

# Construir tabela de folhas
leaves_tbl <- tibble(
    no = as.integer(rownames(frame)[leaves_idx]),
    n = frame$n[leaves_idx],
    n_melhora = frame$n[leaves_idx] * frame$yval2[leaves_idx, 5],
    n_nao_melhora = frame$n[leaves_idx] * frame$yval2[leaves_idx, 4],
    prop_melhora = frame$yval2[leaves_idx, 5],
    predicao = ifelse(frame$yval[leaves_idx] == 2, "melhora", "nao_melhora")
) |>
    rowwise() |>
    mutate(regras = get_path_rules(cart_rpart, no)) |>
    ungroup() |>
    mutate(
        prop_melhora_pct = scales::percent(prop_melhora, accuracy = 0.1),
        grupo = paste0("Grupo ", row_number())
    ) |>
    select(grupo, predicao, n, prop_melhora_pct, regras) |>
    arrange(desc(predicao), desc(n))

leaves_tbl |>
    rename(
        Grupo = grupo,
        Predicao = predicao,
        N = n,
        `% Melhora` = prop_melhora_pct,
        Regras = regras
    ) |>
    knitr::kable(align = c("l", "l", "r", "r", "l"))
```

### Curva ROC

```{r}
#| label: cart-roc-curve
#| fig-width: 7
#| fig-height: 6

# Curva ROC a partir das predicoes CV
roc_data <- preds_all |>
    roc_curve(truth = delta_cat_cart, .pred_melhora, event_level = "second")

# AUC para o titulo
auc_val <- preds_all |>
    roc_auc(truth = delta_cat_cart, .pred_melhora, event_level = "second") |>
    pull(.estimate)

ggplot(roc_data, aes(x = 1 - specificity, y = sensitivity)) +
    geom_path(linewidth = 1.2, color = "steelblue") +
    geom_abline(linetype = "dashed", color = "gray50") +
    geom_ribbon(aes(ymin = 0, ymax = sensitivity), alpha = 0.1, fill = "steelblue") +
    annotate(
        "text", x = 0.6, y = 0.3,
        label = paste0("AUC = ", round(auc_val, 3)),
        size = 5, fontface = "bold"
    ) +
    labs(
        title = "Curva ROC (CV)",
        subtitle = "Baseada em predicoes agregadas de todos os folds",
        x = "1 - Especificidade (Taxa de Falsos Positivos)",
        y = "Sensibilidade (Taxa de Verdadeiros Positivos)"
    ) +
    coord_equal() +
    theme_minimal(base_size = 12) +
    theme(plot.title = element_text(face = "bold"))
```

### Interpretacao

**Como ler a arvore:**

- Cada **no interno** representa uma condicao (split) sobre uma variavel.
- Cada **caminho** da raiz ate um no terminal representa uma **regra** de classificacao.
- A **sequencia de splits** indica **interacoes condicionais**: um split so importa dentro da regiao definida por splits anteriores.
- Os **limiares** (pontos de corte) sugerem **nao-linearidades** nos efeitos.

**Como ler a importancia:**

- Variaveis com maior importancia contribuem mais para a reducao de impureza (Gini) nos splits.
- Isso **nao implica causalidade**, apenas relevancia preditiva no contexto do modelo.

**Limitacoes:**

- Desempenho reportado e **interno** (CV), sem validacao externa.
- Arvores sao **instaveis**: pequenas mudanças nos dados podem alterar a estrutura.
- Usar como **ferramenta exploratoria** complementar aos modelos inferenciais (linear/logistico).

## Modelo de regressão linear

Este modelo estima associações ajustadas com o desfecho contínuo $\Delta$ (maior curva em 6 meses − baseline, em graus).


```{r}
model_lin <- lm(
    delta ~
        idade +
        altura +
        peso +
        # imc +
        cifose_toracica +
        lordose_lombar +
        dif_colete +
        correcao_colete +
        escoliometro +
        inclinacao +
        cifose_categ +
        sexo +
        regiao +
        lenke +
        risser,
    data = df
)
```



### Parâmetros do modelo

```{r}
model_lin |>
    gtsummary::tbl_regression(conf.level = 0.95) |>
    # gtsummary::add_global_p() |>
    gtsummary::bold_p() |>
    gtsummary::bold_labels() |>
    gtsummary::italicize_levels()
```

### Verificações de adequação do modelo

#### Colinearidade

Verificação de colinearidade entre as variáveis independentes (_Variance Inflation Factor_).
Valores maiores que 10 indicam colinearidade entre as variáveis.

```{r}
performance::check_collinearity(model_lin) |>
    arrange(desc(VIF)) |>
    select(Term, VIF, VIF_CI_low, VIF_CI_high) |>
    performance::print_html()

performance::check_collinearity(model_lin) |> plot()
```



#### Heteroscedasticidade

Verificação de heteroscedasticidade entre as variáveis independentes.

```{r}
performance::check_heteroscedasticity(model_lin)
performance::check_heteroscedasticity(model_lin) |> plot()
```


#### Outliers

```{r}
performance::check_outliers(model_lin)
performance::check_outliers(model_lin) |> plot()
```


#### Valores ajustados (diagnóstico)

```{r}
performance::check_predictions(model_lin) |> plot()
```


#### Resíduos simulados

```{r}
performance::check_residuals(model_lin)
performance::check_residuals(model_lin) |> plot()
```


### Qualidade do ajuste do modelo

#### Coeficiente de determinação

$R^2$.
```{r}
# Qualidade do ajuste
performance::r2(model_lin)
```

#### Tamanho amostral efetivo (casos completos)

```{r}
tibble(n_modelo = nobs(model_lin))
```
